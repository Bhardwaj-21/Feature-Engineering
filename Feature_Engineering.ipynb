{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "- In feature engineering, you often apply transformations, encodings, or extract features from raw data. Parameters are the configurable parts of those processes.\n",
        "\n",
        "2. What is correlation?\n",
        "What does negative correlation mean?\n",
        "\n",
        "- Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "\n",
        "- It tells you how much one variable changes in relation to another.\n",
        "The most common measure is Pearson correlation, which ranges from -1 to +1.\n",
        "\n",
        "- A negative correlation means that as one variable increases, the other tends to decrease.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "- Machine Learning is a branch of artificial intelligence (AI) that allows systems to learn patterns from data and make decisions or predictions without being explicitly programmed.\n",
        "\n",
        "- Main Components:\n",
        "- Data – Input used to train the model (features and labels).\n",
        "- Features – Variables used to make predictions.\n",
        "- Model – The mathematical structure that makes predictions.\n",
        "- Algorithm – The method used to train the model.\n",
        "- Training – The process of learning patterns from data.\n",
        "- Loss Function – Measures prediction error.\n",
        "- Evaluation – Tests model performance using metrics.\n",
        "- Testing Data – Unseen data used to check accuracy.\n",
        "- Hyperparameters – Settings that control training behavior.\n",
        "- Deployment – Using the model in real applications.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "- The loss value measures how far off the model’s predictions are from the actual values.\n",
        "\n",
        "- Low loss = Model predictions are close to actual values → Good model\n",
        "High loss = Model predictions are far off → Poor model\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "\n",
        "- Continuous Variables:\n",
        "Numeric values with an infinite range.\n",
        "Can take any value within a range.\n",
        "Examples:\n",
        "\n",
        "Height (e.g., 170.5 cm)\n",
        "Income (e.g., $45,000.75)\n",
        "Temperature\n",
        " Categorical Variables:\n",
        "Represent categories or labels.\n",
        "Values are discrete and often non-numeric.\n",
        "Examples:\n",
        "\n",
        "Gender (Male, Female)\n",
        "Color (Red, Blue, Green)\n",
        "Education Level (High School, Bachelor’s, Master’s)\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "- How to Handle Categorical Variables:\n",
        "- Label Encoding – Assigns a unique number to each category.\n",
        "Use for ordered categories.\n",
        "- One-Hot Encoding – Creates binary columns for each category.\n",
        "Use for unordered categories.\n",
        "- Ordinal Encoding – Numbers reflect category order.\n",
        "Use for ranked data.\n",
        "- Target Encoding – Replace category with average of target variable.\n",
        "Use carefully to avoid overfitting.\n",
        "- Frequency Encoding – Replace category with its frequency count.\n",
        "Useful for many categories.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "\n",
        "- Training vs. Testing a Dataset:\n",
        "Training Dataset:\n",
        "Used to teach the model by finding patterns in the data.\n",
        "Testing Dataset:\n",
        "Used to evaluate the model's performance on unseen data.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "\n",
        "- sklearn.preprocessing is a module in the scikit-learn library that provides tools to transform and scale data before feeding it into machine learning models.\n",
        "\n",
        "9. What is a Test set?\n",
        "\n",
        "- A Test set is a portion of the dataset kept separate from training and used to evaluate the final performance of a trained machine learning model on new, unseen data.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "- test_size=0.2 means 20% data for testing, 80% for training.\n",
        "random_state ensures reproducibility.\n",
        "\n",
        "How to approach a Machine Learning problem:\n",
        "- Understand the problem\n",
        "- Collect and explore data\n",
        "- Preprocess and clean data\n",
        "- Feature engineering/selection\n",
        "- Split data (train/test)\n",
        "- Choose and train model\n",
        "- Evaluate model performance\n",
        "- Tune hyperparameters\n",
        "- Deploy the model\n",
        "- Monitor and maintain\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "- We perform Exploratory Data Analysis (EDA) before fitting a model to:\n",
        "\n",
        "Understand the data — identify patterns, distributions, and relationships.\n",
        "Detect data quality issues — missing values, outliers, errors.\n",
        "Inform feature engineering — choose or create useful features.\n",
        "Select appropriate models — based on data characteristics.\n",
        "Avoid mistakes — like leakage or biased data.\n",
        "\n",
        "12. How can you find correlation between variables in Python?\n",
        "\n",
        "- You calculate correlation by measuring how two variables move together, often using Pearson’s correlation coefficient. In Python, libraries like Pandas provide functions to compute this easily.\n",
        "\n",
        "13. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "- Causation means one event directly causes another to happen.\n",
        "\n",
        "Difference:\n",
        "\n",
        "Correlation: Two variables move together but may not cause each other.\n",
        "Causation: One variable actually causes the change in the other.\n",
        "Example:\n",
        "\n",
        "Correlation: Ice cream sales and drowning incidents both increase in summer — they’re correlated but one doesn’t cause the other.\n",
        "Causation: Smoking causes an increased risk of lung cancer — smoking directly affects cancer risk.\n",
        "\n",
        "14. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "- Optimizer: An algorithm that adjusts model parameters (like weights) to minimize the loss function during training.\n",
        "\n",
        "Common Types:\n",
        "\n",
        "Gradient Descent (GD):\n",
        "Updates parameters by moving opposite to the gradient of the loss.\n",
        "Example: Used in simple linear regression.\n",
        "Stochastic Gradient Descent (SGD):\n",
        "Updates parameters using one data point at a time, faster but noisier.\n",
        "Example: Training large neural networks.\n",
        "Mini-batch Gradient Descent:\n",
        "Uses small batches of data to update parameters, balancing speed and stability.\n",
        "Example: Most deep learning frameworks use this.\n",
        "Adam (Adaptive Moment Estimation):\n",
        "Combines momentum and adaptive learning rates for faster convergence.\n",
        "Example: Popular for training deep neural networks.\n",
        "\n",
        "15. What is sklearn.linear_model ?\n",
        "\n",
        "- sklearn.linear_model is a module in scikit-learn that provides linear models for regression and classification tasks, like Linear Regression, Logistic Regression, and more.\n",
        "\n",
        "16. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "- model.fit() trains the machine learning model by learning patterns from the data.\n",
        "\n",
        "Arguments:\n",
        "\n",
        "X: Input features (usually a 2D array or DataFrame)\n",
        "y: Target labels or values (usually a 1D array or Series)\n",
        "\n",
        "17. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "model.predict() uses the trained model to make predictions on new input data.\n",
        "\n",
        "Argument:\n",
        "\n",
        "X: Input features for which you want predictions (2D array or DataFrame).\n",
        "\n",
        "18. What are continuous and categorical variables?\n",
        "\n",
        "- Continuous variables: Numeric values that can take any value within a range (e.g., height, temperature).\n",
        "\n",
        "Categorical variables: Variables with distinct categories or groups (e.g., gender, color).\n",
        "\n",
        "19. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "- Feature scaling is the process of normalizing or standardizing features so they have similar ranges or distributions.\n",
        "\n",
        "How it helps:\n",
        "\n",
        "Prevents features with large ranges from dominating the model.\n",
        "Speeds up convergence during training.\n",
        "Improves model performance and stability, especially for algorithms like gradient descent, SVM, and KNN.\n",
        "\n",
        "20. How do we perform scaling in Python?\n",
        "\n",
        "- We perform scaling in Python using scikit-learn’s preprocessing tools like StandardScaler or MinMaxScaler.\n",
        "\n",
        "You fit the scaler on training data and then transform both training and test data.\n",
        "\n",
        "21. What is sklearn.preprocessing?\n",
        "\n",
        "- sklearn.preprocessing is a module in scikit-learn that provides tools to transform and scale data before training machine learning models. It includes functions for scaling, encoding, normalizing, and generating features.\n",
        "\n",
        "22. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "- Use train_test_split from sklearn.model_selection to split data into training and testing sets.\n",
        "\n",
        "23. Explain data encoding?\n",
        "\n",
        "- Data encoding is converting categorical data into numerical format so machine learning models can process it.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zeWqtEFI3EnF"
      }
    }
  ]
}